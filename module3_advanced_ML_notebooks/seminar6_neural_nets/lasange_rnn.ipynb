{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import os\n",
    "#thanks @keskarnitish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#тут будет текст\n",
    "corpora = \"\"\n",
    "\n",
    "#with open(\"nietzsche.txt\") as fin:\n",
    "with open(\"Call_Him_Lord_by_R_Gordon_Dickson.txt\") as fin:\n",
    "    text = fin.read()#.decode('cp1251')\n",
    "    corpora += text\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#тут будут все уникальные токены (буквы, цифры)\n",
    "tokens = set(corpora)\n",
    "\n",
    "tokens = list(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {token:id for id, token in enumerate(tokens)}\n",
    "id_to_token = {id:token for token, id in token_to_id.iteritems()}\n",
    "\n",
    "#Преобразуем всё в токены\n",
    "corpora_ids = map(lambda x: token_to_id[x], corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_random_batches(source,n_batches=10, seq_len=20):\n",
    "    \"\"\"Функция, которая выбирает случайные тренировочные примеры из корпуса текста в токенизированном формате.\n",
    "    \n",
    "    source - массив целых чисел - номеров токенов в корпусе (пример - corpora_ids)\n",
    "    n_batches - количество случайных подстрок, которые нужно выбрать\n",
    "    \n",
    "    seq_len - длина одной подстроки без учёта ответа\n",
    "    \n",
    "    \n",
    "    Вернуть нужно кортеж (X,y), где\n",
    "    \n",
    "    X - матрица, в которой каждая строка - подстрока длины [seq_len].\n",
    "    \n",
    "    y - вектор, в котором i-тое число - символ следующий в тексте сразу после i-той строки матрицы X\n",
    "    \n",
    "    Проще всего для этого сначала создать матрицу из строк длины seq_len+1,\n",
    "    а потом отпилить от неё последний столбец в y, а все остальные - в X\n",
    "    \n",
    "    Если делаете иначе - пожалуйста, убедитесь, что в у попадает правильный символ, ибо позже эту ошибку \n",
    "    будет очень тяжело заметить.\n",
    "    \n",
    "    Также убедитесь, что ваша функция не вылезает за край текста (самое начало или конец текста).\n",
    "    \n",
    "    Следующая клетка проверяет часть этих ошибок, но не все.\n",
    "    \"\"\"\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    for i in range(n_batches):\n",
    "        start = np.random.randint(0,len(source) - (seq_len + 1))\n",
    "        stop = start + seq_len\n",
    "        X_batch.append(source[start:stop])\n",
    "        y_batch.append(source[stop:stop + 1])\n",
    "    X_batch = np.array(X_batch)\n",
    "    y_batch = np.array(y_batch)\n",
    "    return X_batch, y_batch\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#длина последоватеьности при обучении (как далеко распространяются градиенты)\n",
    "seq_length = 5\n",
    "\n",
    "# Максимальный модуль градиента\n",
    "grad_clip = 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Входные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('input sequence','int32')\n",
    "target_values = T.ivector('target y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Соберём нейросеть\n",
    "\n",
    "Вам нужно создать нейросеть, которая принимает на вход последовательность из seq_length токенов, обрабатывает их и выдаёт вероятности для seq_len+1-ого токена.\n",
    "\n",
    "Общий шаблон архитектуры такой сети -\n",
    "\n",
    "\n",
    "* Вход\n",
    "* Обработка входа\n",
    "* Рекуррентная нейросеть\n",
    "* Вырезание последнего состояния\n",
    "* Обычная нейросеть\n",
    "* Выходной слой, который предсказывает вероятности весов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_in = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "\n",
    "nn = lasagne.layers.EmbeddingLayer(l_in, input_size=len(tokens), output_size=128)\n",
    "\n",
    "nn = lasagne.layers.LSTMLayer(nn, num_units=512, grad_clipping=grad_clip)\n",
    "\n",
    "nn = lasagne.layers.SliceLayer(nn, -1, 1)\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(nn, num_units=len(tokens), nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W, b]\n"
     ]
    }
   ],
   "source": [
    "# Веса модели\n",
    "weights = lasagne.layers.get_all_params(l_out,trainable=True)\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_output = lasagne.layers.get_output(l_out)\n",
    "#если вы используете дропаут - не забудьте продублировать всё в режиме deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = T.nnet.categorical_crossentropy(network_output,target_values).mean()\n",
    "\n",
    "updates = lasagne.updates.rmsprop(loss, weights, learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Компилируем всякое-разное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#обучение\n",
    "train = theano.function([input_sequence, target_values], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#функция потерь без обучения\n",
    "compute_cost = theano.function([input_sequence, target_values], loss, allow_input_downcast=True)\n",
    "\n",
    "# Вероятности с выхода сети\n",
    "probs = theano.function([input_sequence],network_output,allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем своего Ницше (или Гордона Диксона)\n",
    "\n",
    "* Для этого последовательно применяем нейронку к своему же выводу.\n",
    "\n",
    "* Генерировать можно по разному -\n",
    " * случайно пропорционально вероятности,\n",
    " * только слова максимальной вероятностью\n",
    " * случайно, пропорционально softmax(probas*alpha), где alpha - \"жадность\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_sample_fun(probs):\n",
    "#     print 'probs'\n",
    "#     print probs\n",
    "    return np.argmax(probs) \n",
    "\n",
    "def proportional_sample_fun(probs):\n",
    "    \"\"\"Сгенерировать следующий токен (int32) по предсказанным вероятностям.\n",
    "    \n",
    "    probs - массив вероятностей для каждого токена\n",
    "    \n",
    "    Нужно вернуть одно целове число - выбранный токен - пропорционально вероятностям\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return np.random.choice(len(probs), 1, p=probs)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The next function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "# The phrase is set using the variable generation_phrase.\n",
    "# The optional input \"N\" is used to set the number of characters of text to predict. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_sample(sample_fun,seed_phrase=None,N=200):\n",
    "    '''\n",
    "    Сгенерировать случайный текст при помощи сети\n",
    "\n",
    "    sample_fun - функция, которая выбирает следующий сгенерированный токен\n",
    "    \n",
    "    seed_phrase - фраза, которую сеть должна продолжить. Если None - фраза выбирается случайно из corpora\n",
    "    \n",
    "    N - размер сгенерированного текста.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    if seed_phrase is None:\n",
    "        start = np.random.randint(0,len(corpora)-seq_length)\n",
    "        seed_phrase = corpora[start:start+seq_length]\n",
    "        print \"Using random seed:\",seed_phrase\n",
    "    while len(seed_phrase) < seq_length:\n",
    "        seed_phrase = \" \"+seed_phrase\n",
    "    if len(seed_phrase) > seq_length:\n",
    "        seed_phrase = seed_phrase[len(seed_phrase)-seq_length:]\n",
    "    #assert type(seed_phrase) is unicode\n",
    "        \n",
    "        \n",
    "    sample_ix = []\n",
    "    x = map(lambda c: token_to_id.get(c,0), seed_phrase)\n",
    "    x = np.array([x])\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Pick the character that got assigned the highest probability\n",
    "        ix = sample_fun(probs(x).ravel())\n",
    "        # Alternatively, to sample from the distribution instead:\n",
    "        # ix = np.random.choice(np.arange(vocab_size), p=probs(x).ravel())\n",
    "        sample_ix.append(ix)\n",
    "        x[:,0:seq_length-1] = x[:,1:]\n",
    "        x[:,seq_length-1] = 0\n",
    "        x[0,seq_length-1] = ix \n",
    "\n",
    "    random_snippet = seed_phrase + ''.join(id_to_token[ix] for ix in sample_ix)    \n",
    "    print(\"----\\n %s \\n----\" % random_snippet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random seed: ad pa\n",
      "----\n",
      " ad parpY???ipp6pjY11ENGGgKeePPIIh;;;!VVVshvOBywF\n",
      "R ots/Y?iDpeJ11uh;;l!aaa//9/9;;;;l!aaa//9/9;;;;l!aaa//9/9;;;;l!aaa//9/9;;;;l!aaa//9/9;;;;l!aaa//9/9;;;;l!aaa//9/9;;;;l!aaa//9/9;;;;l!aaa//9/9;;;;l!aaa//9/9; \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "generate_sample(max_sample_fun,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "\n",
    "В котором вы можете подёргать параметры или вставить свою генерирующую функцию.\n",
    "Обучение идёт долго, для демонстрации можно прервать раньше, эту модель всё равно можно будет использовать. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: .\n",
      "The\n",
      "----\n",
      " .\n",
      "The Prince sand be and tibl trosp, and in. He said Kyle and right alove it ho br\n",
      "at his on cas\n",
      "up with threas, what he wish tresing his halt\n",
      "rus one ship feally him.?\"He as the look fory.\n",
      "He Crosh his do \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: ealed\n",
      "----\n",
      " ealed and the said Kyle and the said Kyle and the said Kyle and the said Kyle and the said Kyle and the said Kyle and the said Kyle and the said Kyle and the said Kyle and the said Kyle and the said Kyle a \n",
      "----\n",
      "Epoch 0 average loss = 2.32152365072\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: aken \n",
      "----\n",
      " aken toge tol the me.\" to it Kyli ked sind ey ?\" I's yag ie ~ris\n",
      "to he He his toot on oe the rashfart shiserstand. Ttr he hil drinc of towked toos man.\n",
      "\"Thet to he beid falie. ten's abeos at ope ee tohit\n",
      "s \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: lion'\n",
      "----\n",
      " lion's to he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he he  \n",
      "----\n",
      "Epoch 1 average loss = 2.21667675534\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: can g\n",
      "----\n",
      " can gacked of wote heeepst of wittangpseandes\n",
      "sodeMsopeeht!me softlentteles. BuddeThe\n",
      "and-He me to boyse.\" . WerrideHe of seegtingdeM. He Ands\n",
      "hisseg.  bowle to withe ploteed,  ands-noudds, sadd, bo to Wur \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: d\n",
      "a g\n",
      "----\n",
      " d\n",
      "a godentee to boysee seat to lokenting to lokenting to lokenting to lokenting to lokenting to lokenting to lokenting to lokenting to lokenting to lokenting to lokenting to lokenting to lokenting to loken \n",
      "----\n",
      "Epoch 2 average loss = 2.28630908547\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: h mis\n",
      "----\n",
      " h mis fackl'ss letting get the colky,r's .Dolt. meth, sandly, un his yor~;\n",
      "wanht lefelet, the gar. cims than's was sead-cand if ungeld slyesen, wink netht Ie tho lPr, wat.\n",
      "\"an cist back wot thete fack for  \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: n its\n",
      "----\n",
      " n itsere stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk the stalk  \n",
      "----\n",
      "Epoch 3 average loss = 2.1223847442\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: is ap\n",
      "----\n",
      " is aporspenting was she sd'und\n",
      "Ofd thensed and was tho\n",
      "mory aiden\"R. The dor, I me they the ployh\n",
      "nect hing couging asdedf\n",
      "boeu.\"\n",
      "\"And pun,\" said,\" he was was was word as\n",
      "und you bopoGeand\n",
      " onnssked\n",
      "or stn \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: ht, t\n",
      "----\n",
      " ht, the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was the was t \n",
      "----\n",
      "Epoch 4 average loss = 2.17944597971\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: k fro\n",
      "----\n",
      " k frope I he sceos the saisifd,\" han.\"\n",
      "w offle, h; saide \n",
      "it-atisaifple  a rone,\"  thate,\" said Kyle,-1en towis.p\"\" he ans Kyle witchese \n",
      "aful ar tha upter rsid tienI hhes aredd wind any hrowntcaneere hand \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed:  at h\n",
      "----\n",
      "  at hand toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toungen toun \n",
      "----\n",
      "Epoch 5 average loss = 2.09664557642\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: Their\n",
      "----\n",
      " Theirt. \"lodkbothat. sold, a stassted but the ut the youd manter bror maasly. \"The cut the me sauddn-lanut eotle. said Kyle, was oust. He dory to willowerstingedser bonortowit lode mor the the do moringly. \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: . Loo\n",
      "----\n",
      " . Lood was the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the th \n",
      "----\n",
      "Epoch 6 average loss = 2.08560677046\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: out o\n",
      "----\n",
      " out otd and he whaut's in'singtinH. \". the git'se on cavester ons Gaterad and fcenked to slfand ossing. Prince the tret /ter a war. wer~ed the of hos and werseding handtIn, the;\n",
      "biGt lifgry warh trostPrdGw \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: hundr\n",
      "----\n",
      " hundrend and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and  \n",
      "----\n",
      "Epoch 7 average loss = 2.04533685233\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: head.\n",
      "----\n",
      " head.\n",
      "\"Del wath thecl thheis. The lyOme yorng al he biits ur. Jit he to rome\n",
      "ays, wartKyou\n",
      "ha. sme&int becthp, fveorifge -thour the  baitre thand teititter, s his he garked And thatkem, hand\n",
      "hind.\n",
      "hee . ha \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: eakin\n",
      "----\n",
      " eaking handly the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "----\n",
      "Epoch 8 average loss = 2.12366956192\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: ing d\n",
      "----\n",
      " ing di!\" said trewas wained, InsmKyle t und lighse, \n",
      "fremou tuck trets.\n",
      "Bugh see\n",
      "haod\n",
      "tookw\n",
      "thae,\" said.\n",
      "So\n",
      "peat an ix.\n",
      ",\n",
      "to. U\n",
      "UDoKyle gand hant alsed,\" said the onle nunk wellly ild tot in tiookr at. You \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: the w\n",
      "----\n",
      " the waill to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to inter to int \n",
      "----\n",
      "Epoch 9 average loss = 1.98645373713\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: r fri\n",
      "----\n",
      " r frix\"you the b'rny-\n",
      "but the youardNs htadmered ordight a\n",
      "the gral awlat\n",
      "stannionche aus , man. Re ues prcart of urordinnd the knowind oSh bay on the hind chind baxch hade al, he bight , reaCt undibgtped  \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: ming \n",
      "----\n",
      " ming the stallion the stallion the stallion the stallion the stallion the stallion the stallion the stallion the stallion the stallion the stallion the stallion the stallion the stallion the stallion the s \n",
      "----\n",
      "Epoch 10 average loss = 2.00825338182\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: let-h\n",
      "----\n",
      " let-handle shad dolkty. \"Cound doBk a loobKyle wan it the Princeed. \"Ther have the Prince. \"Nook shanding, himh a sair to the on the Ppinch\n",
      "iban yougs the Prance. \"Telldsing\" said. \"Non a ay his kisht do l \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: \" sai\n",
      "----\n",
      " \" said. \"No the Prince. \"No the Prince. \"No the Prince. \"No the Prince. \"No the Prince. \"No the Prince. \"No the Prince. \"No the Prince. \"No the Prince. \"No the Prince. \"No the Prince. \"No the Prince. \"No t \n",
      "----\n",
      "Epoch 11 average loss = 1.93120591867\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed:  me m\n",
      "----\n",
      "  me manchinchand sof his envee heariunaing throw csogl\n",
      "mace ourned urned the toxd\n",
      "iutcanosnownty wo fill  ethar on veoway for\n",
      "on the gutet of of there. The durnu, dop can's Bard, .uencer sto the Prince sou \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: ing b\n",
      "----\n",
      " ing body of the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Prince the Pr \n",
      "----\n",
      "Epoch 12 average loss = 1.98403123285\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: ss, w\n",
      "----\n",
      " ss, we. .\" you the\n",
      "lattr anes theress and thret back. \"Lord, you indre.\n",
      "\"I dow. The threamimeing handbhthere. JeBd, backs.\n",
      "\"~o tamor the read eves ie ulsalendy pon thout a soffer eyes fidder we rehmup wors \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: ott,\"\n",
      "----\n",
      " ott,\" said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the s \n",
      "----\n",
      "Epoch 13 average loss = 2.01706324815\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed:  room\n",
      "----\n",
      "  room his rothnhif voiterre.\n",
      "He rout Tyou reseenseroe ceeting the me aysavy to the reme.\" The baHe a melare a I an a Kyle. Kyle io's eac bar fmoimoto and acrasRlownere a lotting a roi. pR you oJ you wo\n",
      "lot \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: as th\n",
      "----\n",
      " as the he said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I said Kyle. \"I \n",
      "----\n",
      "Epoch 14 average loss = 1.99380622423\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: yes l\n",
      "----\n",
      " yes like dowhwith a aiseaet. Hiseretsayeriancewasen aving, monged, as arounderatereslo? ee said the\n",
      "Pnince, row. And in the\n",
      "rip to the\n",
      "r me. youlge wasth stroked of the in's breserieseielitring hime a nobo \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed:  he\n",
      "s\n",
      "----\n",
      "  he\n",
      "stroke throw the Prince stroke throw the Prince stroke throw the Prince stroke throw the Prince stroke throw the Prince stroke throw the Prince stroke throw the Prince stroke throw the Prince stroke th \n",
      "----\n",
      "Epoch 15 average loss = 1.97336303649\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: e tea\n",
      "----\n",
      " e teatoke ac\n",
      "yol to to fhouldode aed\n",
      "nowdy wsra'd i a the quet the Prince mery the drow him thdoke oarbed the Edinding he Ret's teod oatoreghr\n",
      "flilf you dow dibe the  tat'lighoutafder and the arhe light of \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: light\n",
      "----\n",
      " light to the Prince said, and the Prince said, and the Prince said, and the Prince said, and the Prince said, and the Prince said, and the Prince said, and the Prince said, and the Prince said, and the Pri \n",
      "----\n",
      "Epoch 16 average loss = 1.97371974679\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: d. We\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-ec8bdef1e813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Генерируем текст в пропорциональном режиме\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgenerate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproportional_sample_fun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Генерируем текст в жадном режиме (наиболее вероятные буквы)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-ff8bd6c57714>\u001b[0m in \u001b[0;36mgenerate_sample\u001b[0;34m(sample_fun, seed_phrase, N)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Pick the character that got assigned the highest probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Alternatively, to sample from the distribution instead:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# ix = np.random.choice(np.arange(vocab_size), p=probs(x).ravel())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/artem/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/artem/.local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/artem/.local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/artem/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-2.7.12-64/scan_perform/mod.cpp:6489)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/artem/.local/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mvalue_zeros\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \"\"\"\n\u001b[1;32m    631\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training ...\")\n",
    "\n",
    "\n",
    "#сколько всего эпох\n",
    "n_epochs=500\n",
    "\n",
    "# раз в сколько эпох печатать примеры \n",
    "batches_per_epoch = 100\n",
    "\n",
    "#сколько цепочек обрабатывать за 1 вызов функции обучения\n",
    "batch_size=10\n",
    "\n",
    "\n",
    "for epoch in xrange(n_epochs):\n",
    "\n",
    "    print \"Генерируем текст в пропорциональном режиме\"\n",
    "    generate_sample(proportional_sample_fun,None)\n",
    "    \n",
    "    print \"Генерируем текст в жадном режиме (наиболее вероятные буквы)\"\n",
    "    generate_sample(max_sample_fun,None)\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in range(batches_per_epoch):\n",
    "        \n",
    "        x,y = sample_random_batches(corpora_ids,batch_size,seq_length)\n",
    "        avg_cost += train(x, y[:,0])\n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " wards.\n",
      "\"Ankteroyease tick.\"\n",
      "Thegruveny\n",
      " chote.\n",
      "\"Yom\n",
      "i. lewwabrim nigher as the hlfaftHerePringist the will.\n",
      "\"Aforeh, as and bar can not u?\"\n",
      "Kyle\n",
      "ngat ic the dide shat't mac, bung the Prince sunty more\n",
      "mond\n",
      "f\"\n",
      "ipKngsehfiate. said, aseming and you. AGaJd,\" said.\n",
      "\"Anle\n",
      "rean nes. Arrleard\n",
      "ilively to more, sh \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "seed = \"thousands of years afterwards\"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(sampling_fun,seed,result_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " tself ad him. \"? ullackinkt for allifaJking.\n",
      "\"\n",
      "Thetures.\n",
      "\"Prince ta lang a sallike hav more?\"\n",
      "\"I'me fime wgravilleIt herse. I'mqle. The\n",
      "punult, mish be there guatteeh and's hou. \"ken Arebed to be and more liugherd\n",
      "to bicked bodet the t hou n'le clope clong.\n",
      "\"At saddy, sacked didinp bide\n",
      "fack,\n",
      "sstdruviall \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "seed = \"which bravely admits this to itself\"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(sampling_fun,seed,result_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
